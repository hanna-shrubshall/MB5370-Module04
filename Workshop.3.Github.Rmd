---
title: "Workshop.3.Github"
output: html_document
date: "2023-05-04"
Author: Hanna Shurbshall 
---
#2.0 Workshop 1: Dataviv in R 

##2.1 Installing the tidyverse
```{r}
install.packages("tidyverse")
library(tidyverse)
```

##2.5 Obtain the data 
```{r}
mpg
```
##2.6 Create your first ggplot 
- ggplot() creates a coordinate system   that you can add layers to 
- the function "data =" is where you     input your dataset being used for the plot
- geom_point() addds a layer of points   to your plots which creates a scatterplot. 
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```
##2.7 Understand the 'grammar of graphics' 
###2.7.1 Graphing template 
A general template for ggplot is to 'call ggplot, offer it data, then provide a geom function with a collection of mappings, which dictate how you plot will look' 
```{r}
#GGPLOT TEMPLATE 
#ggplot(data = <DATA>) + 
#  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
```

###2.7.2 Aesthetic mappings 
- This refers to the size, shape and colour of data points 
- You need to attributes of a plot a geom and aesthetic 
```{r}
#change point colour by class
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, colour = class))

#Change point size by class
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, size = class))

#Change point transparency by class (alpha)
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))

#change point shape by class
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))

#set colour manually
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = "purple")

#What happens if you map an aesthetic to something other than a variable na,e, like aes(colour = displ <5)? 
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, colour = displ <5))
#It's interesting to note that any number above 5 is coloured orange, where as any colour below 5 is coloured blue. 
```

##2.9 Facet and panel plots 
This section allows you to develop separate plots for a range of reasons, most often to show a subset of data
```{r}
#Using facet wrap
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))+ facet_wrap(~class,nrow = 2)

#Facet grid (more than one variable, using ~ to seperate variables)
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))+ facet_grid(drv~cyl)

#using a . to produce plots without rows or column dimensions
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))+ facet_grid(.~cyl)
```
 
Exercise: 
What does nrow do? 
This dictates the number of rows there are 
what does ncol do? 
This dictates the number of columns there are 
What other options control the layout of the individual panels? 
The function as.table lays the facets out as a table if TRUE with the highest values at the bottom right. if FALSE the facets are laid out like a plot with the highest value at the top right. 

##2.10 Fitting simple lines
```{r}
#Original plot
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) 

# display the same data as a smooth line fir through the points using geom_smooth()
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))

#changing the line type
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))

#set a group aesthetic to a categorical variable to draw multiple objects
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))

#change the colour of each line based on drv value
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, colour = drv), show.legend = FALSE)

#Plotting multiple geoms on the single plot
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))+
  geom_point(mapping = aes(x = displ, y = hwy))

#creating the same plot as above, BUT in a more efficient manner
ggplot(data = mpg, mapping = aes(x = displ, y = hwy))+
  geom_point()+
  geom_smooth()

#using mappings in specific layers to enable the display of different aesthetics in different layers
ggplot(data = mpg, mapping = aes(x = displ, y = hwy))+
  geom_point(mapping = aes(color = class))+
  geom_smooth()

#specify different data for each layer, here a filter is used to select a subset of data and plot only that subset (class = "subcompact")
ggplot(data = mpg, mapping = aes(x = displ, y = hwy))+
  geom_point(mapping = aes(color = class))+
  geom_smooth(data = filter(mpg, class =="subcompact"), se = FALSE)


```

Exercise:
1. What geom would you use to draw a line chart? A boxplot? A histogram? An area chart?
- geom_smooth 
- geom_boxplot
- geom_histogram
- geom_area 

2. Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions.
- it will produce points and line data 

3. Will these two graphs look different? Why/why not?
These two graphs will look the same because the first set of cod is  the more efficient way to write the second lot of code. Hence, they will produce the same map. 

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()

ggplot() + 
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
```

##2.11 Transformations and Stats
The following is going to be using a different data set 
- The diamonds dataset comes in ggplot2 and contains information about ~54,000 diamonds, including the price, carat, color, clarity and cut of each diamond 
- bar charts, histograms, and frequency polygons bin your data and then plot bin counts, the number of points that fall in each bin.
- smoothers fit a model to your data and then plot predictions from the model.
- boxplots compute a robust summary of the distribution and then display a specially formatted box.

The algorithm used to calculate new values for a graph is called a stat, short for statistical transformation. 

###2.11.1 Plotting statistics
```{r}
#Adding a ggplot dataset
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))

#Using geoms and stats interchangeably
ggplot(data = diamonds) + 
  stat_count(mapping = aes(x = cut))
```

###2.11.2 Overriding defaults in ggpplot2
```{r}
#understanding how to override a default stat
demo <- tribble(
  ~cut,         ~freq,
  "Fair",       1610,
  "Good",       4906,
  "Very Good",  12082,
  "Premium",    13791,
  "Ideal",      21551
)
demo

ggplot(data = demo) +
  geom_bar(mapping = aes(x = cut, y = freq), stat = "identity")

#overriding a default mapping from transformed variables to aesthetics (displaying a bar chart of proportion of your total diamond data set rather than a count)
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = after_stat(prop), group = 1))
```

###2.11.3 Plotting statistical details 
```{r}
#understanding more about these transformations in your plot: using stat_summary()
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )

#you need to set the group = x number, otherwise the plots data will be represented as the same
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = after_stat(prop)))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = after_stat(prop)))
```

##2.12 Positional adjustments 
Position adjustments allow you to customise plots in 3 ways: 
1. identity (raw data)
2. fill (changes in heights)
3. dodge (forces ggplot2 to not put things on top of each other)

- position = "identity" means you can place each object exactly where it falls in the context of the graph (good for scatter plots)
```{r}
#using colour or fill to change aspects of bar colours 
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))

#using these aesthetics to colour by clarity: 
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))

#To alter transparency (alpha)
ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = "identity")

#To color the bar outlines with no fill color
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = "identity")

#position = "fill" makes each stacked bar the same height
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")

#position = "dodge" places overlapping objects directly BESIDE one another 
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")

#position = "jitter" adds a small amount of random noise to each point to avoid overplotting when points overlap (useful for scatterplots, not bar graphs)
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")

#
```

##2.13 The layered grammar of graphics 
```{r}
#CREATING GGPLOT TEMPLATE
#ggplot(data = <DATA>)+ 
 # <GEOM_FUNCTION>(
 #    mapping = aes(<MAPPINGS>)),
  #   stat = (<STAT>), 
  #   position = (<POSITION>) +
 # <FACET_FUNCTION>
 
```
----------------------------------------------------

##Workshop 3: Ussing ggplot2 for communication 
##3.1 Labels 
```{r}
#adding labels to ggplots are important for communicating what you are plotting. This eaxmple is inputting a title
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(title = "Fuel efficiency generally decreases with engine size")

#adding more text
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Fuel efficiency generally decreases with engine size",
    subtitle = "Two seaters (sports cars) are an exception because of their light weight",
    caption = "Data from fueleconomy.gov"
  )

#using labs() to replace axis label and legend titles
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  labs(
    x = "Engine displacement (L)",
    y = "Highway fuel economy (mpg)",
    colour = "Car type"
  )
```

##3.2 Annotations 
Adding text to the plot itself. 
- geom_text() to ad textual labels to plots 
- geom_point(), rather than a shape geometry it can add a label. 
- the "nudge()" function can be used to mave certain text around so that it isn't overlapping 

```{r}
#adding a label that calls in the values from the data frame
best_in_class <- mpg %>%
  group_by(class) %>%
  filter(row_number(desc(hwy)) == 1)

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_text(aes(label = model), data = best_in_class)
```

##3.3 Scales 

```{r}
#ggplot2 automatically adds scales for you as seen below: 
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))

#Tweaking scales
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  scale_x_continuous(breaks = seq(0, 10, by = 1)) +
  scale_y_continuous(breaks = seq(15, 50, by = 5)) +
  scale_colour_discrete(10)
```

##3.4 Axis ticks 
```{r}
#changing the ticks on the axes
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_y_continuous(breaks = seq(15, 40, by = 5))
```

##3.5 legens and colour schemes 
```{r}
#changing the position of the legend using theme()
base <- ggplot(mpg, aes(displ, hwy))+
  geom_point(aes(colour = class))
base + theme(legend.position = "left")

#can use this and change the position as a way to change the location of the legend
base <- ggplot(mpg, aes(displ, hwy))+
  geom_point(aes(colour = class))
base + theme(legend.position = "top")
```

##3.6 Replacing a scale 
There are two types of scales that are most likely going to be used: contiuous position scales and colour sclaes 
```{r}
#using logtransform to easily visualise data
ggplot(diamonds, aes(carat, price))+
  geom_bin2d()+ 
  scale_x_log10(5)+ 
  scale_y_log10(10)

#changing the colour scale
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv))

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv)) +
  scale_colour_brewer(palette = "Set1")

#adding a redundant shape mapping (this helps to ensure the plot is interpretable in black and white)
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv, shape = drv)) +
  scale_colour_brewer(palette = "Set1")

#predefined colours that you want to use the function scale_colour_manual() can be used
presidential %>%
  mutate(id = 33 + row_number()) %>%
  ggplot(aes(start, id, colour = party)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_colour_manual(values = c(Republican = "red", Democratic = "blue"))

#viridis colour scheme: scale_colour_viridis(), downloading the viridis package 
#install.packages('viridis')
#install.packages('hexbin')
library(viridis)
library(hexbin)

#creating a fake dataset to plot
df <- tibble( 
  x = rnorm(10000),
  y = rnorm(10000)
)
ggplot(df, aes(x, y)) +
  geom_hex() + # a new geom!
  coord_fixed()

ggplot(df, aes(x, y)) +
  geom_hex() +
  viridis::scale_fill_viridis() +
  coord_fixed()
```

##3.7 Themes 
Customising the entire theme of your plot 
- ggplot has 8 themes by default 
 
```{r}
#graph is the BLACK AND WHITE, dark on light ggplot2 theme
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_bw()

#LIGHT GRAY lines and axes, to direct more attention to the data
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_light()

#CLASSIC theme with the x and y axis lines and no gridlines
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_classic()

#graph below is the DARK THEME 
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_dark()

#can develop your own themes by setting more arguments (Nick's example)
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
theme (panel.border = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position="bottom",
        legend.title=element_blank(),
        legend.text=element_text(size=8),
        panel.grid.major = element_blank(),
        legend.key = element_blank(),
        legend.background = element_blank(),
        axis.text.y=element_text(colour="black"),
        axis.text.x=element_text(colour="black"),
        text=element_text(family="Arial")) 
```

##3.8 Saving and exporting your plots 
There are two main ways to export your plots out of R: 
1. Using ggsave()
2. Or export with your code ising R markdown via knitr
```{r}
ggplot(mpg, aes(displ, hwy)) + geom_point()

ggsave("my-plot.pdf")
```

----------------------------------------------------------------
##4.0 Workshop 3: Reproducible work  
Below the code is installing Git
```{r}
install.packages("usethis")
library(usethis)
use_git_config(user.name = "hanna-shrubshall", user.email = "hanna.shrubshall@gmail.com")
```

##4.9.1 Pull
- Pulling a repository simply downloads it from the remote server onto the computer. 
##4.9.2 Stage 
Git stage prepares the file for committing it. 
- The files in the Git tab need to be ticked as standard, meaning you want the files to be sent to your remote repo when you go ahead and commit. 

##4.9.3 Commit 
This is the function that saves this 'version' of your repo into your repository's version history. 
-At this point you can write readable messages of what you've done to your repo. 

##4.9.4 Push 
This is the function that pushes your changes to the remote server 
-It's best practice to commit and push your code at the same time

------------------------------------------------------------------------
##5.0 Workshop 4: Data Wrangling in R
- A tibble is a data frame that is slightly adjusted to help users keep up with the evolving applications of R. 
- Tibbles are different to R's built-in data frame which will be called data.frame S. 
- The tibble package is part of the tidyverse package 

##5.3 WHat is a tibble? 
- R packages use regular data frames. To turn said regular data frames into tibbles you can use the function as_tibble().
- You can also create a new tibble from individual vectors using tibble(). This will automatically recycle inputs of length 1, and allows you to refer to variables that you just created. 
*NOTE, tibble() does not change input types, names of variables or create row names
```{r}
library("tidyverse")
as_tibble(iris)

#example tibble
tibble(
  x = 1:5, 
  y = 1, 
  z = x ^ 2 + y
)

#non-syntactic names in tibble allowed (refer these names with a backstick `)
tb <- tibble(
  `:)` = "smile",
  ` ` = "space", 
  `2000` = "number"
)
tb

#Tribble another way to create a tibble 
tribble(
   ~x, ~y, ~z,
  #Header
  "a", 2, 3.6,
  "b", 1, 8.5
)

tibble(
  a = lubridate::now() + runif(1e3) * 86400,
  b = lubridate::today() + runif(1e3) * 30,
  c = 1:1e3,
  d = runif(1e3),
  e = sample(letters, 1e3, replace = TRUE)
)

#alter default display 
install.packages("nycflights13")
library("nycflights13")
nycflights13::flights %>% 
  print(n = 10, width = Inf)

#You can also control the default print behaviour by setting options
df <- tibble(
  x = runif(5),
  y = rnorm(5)
)

# Extract by name
df$x

df[["x"]]

# Extract by position
df[[1]]

#Need to use a . as a place holder if we want to use these tools in a pipe (%>%)
df %>% .$x
df %>% .[["x"]]

#Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviours cause you frustration?
df <- data.frame(abc = 1, xyz = "a")
df$x
df[, "xyz"]
df[, c("abc", "xyz")]

df <- tibble(abc = 1, xyz = "a")
df$x
df[, "xyz"]
df[, c("abc", "xyz")]


```

What is the difference between tibbles and data.frame? 
- Tibbles print the first 10 rows and all columns that can fit on screen 
- Tibbles also print the type of each data next to its name (character, string, numeric, etc). 
- Tibbles help your console from getting overwhelmed by printing massive data frames. 



##5.4 How can I import data? 
- read_csv() reads comma delimited files
- read_csv2() reads semicolon separated files 
- read_tsv() reads tab delimited files 
- read_delim() reads in files with any delimiter
- read_fwf() reads fixed width files. You can specify fields with their widths with either fwf_widths() or position with fwf_positions()
- read_table reads a common variation of fixed width files where columns are separated by white space. 
- read_log() reads Apache style log files 

Most important argument to read_csv() is the file path.
- when you run read_csv() it prints out a column specification that gives the name and type of each column 

```{r}
#using read_csv()
read_csv("a,b,c
1,2,3
4,5,6")

#Using read_csv() and changing the default 
read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3", skip = 2)

read_csv("# A comment I want to skip
  x,y,z
  1,2,3", comment = "#")

#changing the default if your data has no column names 
read_csv("1,2,3\n4,5,6", col_names = FALSE)

#pass col_names a character vector to be used as the column names
read_csv("1,2,3\n4,5,6", col_names = c("Bob", "Charlie", "Sam"))

#na: this specifies the value (or values) that are used to represent missing values in your file
read_csv("a,b,c\n1,2,.", na = ".")
```

##5.5 Tidying data using Tidyr
```{r}
library(tidyverse)
```

###5.5.1 Tiday data 
There are many ways to display a given data set, but not every way is easy to use for analysis. Note that in the example below, only table1 is “tidy”.
How we make our dataset a tidy dataset is by following three interrelated rules. 
1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

```{r}
#inputting all the data tables 
table1

table2

table3

table4a

table4b

#examples of how you might work with tidy for table1
table1 %>% 
  mutate(rate = cases / population * 10000)

table1 %>% 
  count(year, wt = cases)

library(ggplot2)
ggplot(table1, aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))
```


###5.5.2 Spreading and gathering data tables 
Common problems with untidy data: 
1. One variable is spread across multiple columns
2. One observation is scattered across multiple rows
- to fix said problems the following to functions will be used 
1. pivot_longer() A common problem is a dataset has some column names that are not the names of the variables, but the values of the variables

```{r}
#example table
table4a

#To tidy this type of dataset: 
#- The set of columns whose names are values, not variables. In this example, those are the columns 1999 and 2000.
#- The name of the variable to move the column names to. Here it is year.
#- The name of the variable to move the column values to. Here it’s cases.

#Using pivot_longer()
table4a %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")

table4b %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")

#Combinning the tidied versions of table 4a + 4b into a single tibble 
tidy4a <- table4a %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
tidy4b <- table4b %>% 
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")
left_join(tidy4a, tidy4b)

#pivot_wider()
table2

table2 %>%
    pivot_wider(names_from = type, values_from = count)
```

###5.5.3 Seperating and uniting data tables 
In table 3, there is one column (rate) that has two variables (cases & population). To address this you can use the function separate(), which seperates one column into multiple columns. 

Example below: 
```{r}
#example
table3

#this separates the data into cases and population 
table3 %>% 
  separate(rate, into = c("cases", "population"))

#Both cases and population are listed as character types. This is a default, the values in these columns are actually numbers so we need to convert them to better types by using convert=TRUE
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)

#Can also pass a vector of integers to sep. separate() will interpret the integers as positions to split at. 
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2)

#Can perform the inverse of separate by using unite() to combine multiple columns into a single column.
table5 %>% 
  unite(new, century, year, sep = "")
```

###5.5.4 Handling missing values 
Missing values are either blank or generally filled by NA. 
*NOTE, an "NA" (explicit absence) indicates the presence of absent data. A "blank cell" just indicates the absence of data (implicit absence). 
```{r}
#Example dataset missing two values
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)

#below making implicit values explicit
stocks %>% 
  pivot_wider(names_from = year, values_from = return)

#The explicit missing claues may not be important in other representations of the data, hence you can set values_drop_na=TRUE in pivot_longer() to turn explicit values implicit
stocks %>% 
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(
    cols = c(`2015`, `2016`), 
    names_to = "year", 
    values_to = "return", 
    values_drop_na = TRUE
  )

#Using the complete function - This taks a set of columns and finds all the unique combinations and then ensures the original dataset contains all of those values, including filling in explicit NA where needed.
stocks

stocks %>% 
  complete(year, qtr)

#Similarly, the fill() function can be used to fill in the missing values that were meant to be carried forward. 
 treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)
treatment

treatment %>% 
  fill(person)
```
 

##5.6 Learning relational data
Relations are defined between a pair of tables. All other relations are built up from this simple idea: the relations of three or more tables are always a property of the relations between each pair. Sometimes both elements of a pair can be the same table! This is needed if, for example, you have a table of people, and each person has a reference to their parents.
*NOTE, nycflights13 contains 4 tibbles that are related to flights. 

```{r}
library(tidyverse)
library(nycflights13)

#datasets 
airlines #airlines lets you look up the full carrier name from its abbreviated code

airports #airports give information about each airport, identified by the faa airport code

planes #gives information about each plane, identified by its tailnum

weather #gives the weather at each NYC airport for each hour 
```

###5.6.1 Joining datasets 
To join datasets together you need to identify the keys.
- A key is a variable (or set of variables) that uniquely identifies an observation. 

- There are two types of keys
  1. Primary key, uniquely identifies an observation in its own table
  2. Foreign key, uniquely identifies an observation in another table
  
- Once the primary keys have been identified in your table, its good practice to verify that they do indeed uniquely identify each observation. Using the function count(). 

*NOTE, if a table lacks a primary key, you can add one with mutate() and row_number()

```{r}
#Tables 
planes %>% 
  count(tailnum) %>% 
  filter(n > 1)

weather %>% 
  count(year, month, day, hour, origin) %>% 
  filter(n > 1)

flights %>% 
  count(year, month, day, flight) %>% 
  filter(n > 1)

#the key is tailnumber not flights
flights %>% 
  count(year, month, day, tailnum) %>% 
  filter(n > 1)
```

###5.6.2 Mutating joins 
Mutating a join allows you to combine variables from two tables. 
- it first matches variables by their keys, then copies across variables from one table to the other. 

```{r}
#Narrow subset of data 
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)

#Use of left_join function 
flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier")

#Use of mutate function (creates the same result as previous code)
flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)])

#Dive into how mutating joins work in detail
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)


#output of an inner join containing the key, x & y values
x %>% 
  inner_join(y, by = "key")


#outer join keeps observations that appear in at least one of the tables, there are 3 types: left_join(keeps all observations in x), right_join(keeps all observations in y), full_join(keeps all observations in x and y)
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     1, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2"
)
left_join(x, y, by = "key")

#Both tables have duplicate keys, which is usually an error. When you join duplicated keys, you get all possible combinations = the Cartesian product: 
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     3, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     2, "y3",
     3, "y4"
)
left_join(x, y, by = "key")

#Using the function by to join tables 
flights2 %>% 
  left_join(weather)

flights2 %>% 
  left_join(planes, by = "tailnum")


#specifying what point you want to join 
flights2 %>% 
  left_join(airports, c("dest" = "faa"))

flights2 %>% 
  left_join(airports, c("origin" = "faa"))


```

###5.6.3 Filtering Joins 
```{r}
#Filtering joins 
top_dest <- flights %>%
  count(dest, sort = TRUE) %>%
  head(10)
top_dest

#Constructing a filter 
flights %>% 
  filter(dest %in% top_dest$dest)

#Using a semi_join which connects two tables (only keeps the rows in x that have a match in y)
flights %>% 
  semi_join(top_dest)

#Anti_join are the inverse of semi_joins they keep rows without matches. Great for diagnosing mismatches in a dataset. 
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(tailnum, sort = TRUE)



```

##5.7 Pipes for more readable workflows 
Pipes are a tool that allow us to elegantly code data wrangling steps into a series of sequential actions on a single data frame.
```{r}
library(magrittr)

#Adding in a dataset
foo_foo <- little_bunny()

#saving each step as a new object 
foo_foo_1 <- hop(foo_foo, through = forest)
foo_foo_2 <- scoop(foo_foo_1, up = field_mice)
foo_foo_3 <- bop(foo_foo_2, on = head)

#Overwriting the original object instead of creating intermediate objects at each step
foo_foo <- hop(foo_foo, through = forest)
foo_foo <- scoop(foo_foo, up = field_mice)
foo_foo <- bop(foo_foo, on = head)

#string the function calls together 
bop(
  scoop(
    hop(foo_foo, through = forest),
    up = field_mice
  ), 
  on = head
)

#Use a pipe 
foo_foo %>%
  hop(through = forest) %>%
  scoop(up = field_mice) %>%
  bop(on = head)

#pipe wont work for two classes of functions 
#1. functions that use the current environment Assign()
assign("x", 10)

"x" %>% assign(100)
x

env <- environment()
"x" %>% assign(100, envir = env)
x
#2. Functions that use lazy evaluation 
tryCatch(stop("!"), error = function(e) "An error")

stop("!") %>% 
  tryCatch(error = function(e) "An error")
```

----------------------------------------------------------
##6.0 Workshop 5: Spatial data in R 

##6.4 Installing the spatial R packages 
```{r}
#install necessary packages
#install.packages("sf")
#install.packages("terra")
#install.packages("leaflet")
#install.packages("tmap")

#load into R library
library(tidyverse)
library(sf)
library (terra)
library(leaflet)
library(tmap)
library(mgcv)
```

##6.5 Introduction to the problem 
https://www.seascapemodels.org/spatial-analysis-in-r/spatial-analysis-in-r.html)

##6.6 Loading the spatial dataset 
```{r}
#load the copepod data into R studio
library(readr)
dat <- read_csv("E:/github (1)/github/MB5370-Module04/data/data-for-course/copepods_raw.csv")
dat
```

##6.7 Data exploration 
###6.7.1 Check Coordinates 
```{r}
library(ggplot2)

#first plot of the coordinates 
ggplot(dat) + 
  aes(x = longitude, y = latitude, color = richness_raw) +
  geom_point()

#Looking at richness data (main variable for analysis)
ggplot(dat, aes(x = latitude, y = richness_raw)) + 
  stat_smooth() + 
  geom_point()
```
##6.8 Getting going with maps 
```{r}
#Turn the data into a simple features collection 
sdat <- st_as_sf(dat, coords = c("longitude", "latitude"), 
                 crs = 4326)
```

##6.9 Coordinate systems 
```{r}
#Coordinate system 
crs4326 <- st_crs(4326)
crs4326 # look at the whole CRS
crs4326$Name # pull out just the name of the crs


#Looking at the WKT 
crs4326$wkt # crs in well-known text format
```

##6.10 Feature collection (points)
```{r}
#Looking at what the sdat created 
sdat

#NOTE this is similar to a shapefile 
```

##6.11 Cartography 
```{r}
#mapping the data
plot(sdat["richness_raw"])

#Plotting sdat, creates a panel for every variable in the dataframe 
plot(sdat)
```

##6.12 Thematic maps for communication 
```{r}
#Using tmap 
tm_shape(sdat) + 
  tm_dots(col = "richness_raw")

#Using tamp_save() to save the map to the working directory 
tmap_save(tm1, filename = "Richness-map.png", 
          width = 600, height = 600)
```

##6.13. Mapping and spatial polygons as layers 

###6.13.1 Loading shapefiles 
```{r}
#reading course shape file 
aus <- st_read("E:/github (1)/github/MB5370-Module04/data/data-for-course/spatial-data/Aussie/Aussie.shp")

#reading aus_shelf shape file 
shelf <- st_read("E:/github (1)/github/MB5370-Module04/data/data-for-course/spatial-data/aus_shelf/aus_shelf.shp")

#Checking the data 
aus
```
###6.13.2 Mapping your polygons 
```{r}
#this creates the map of Australia 
tm_shape(shelf) + 
  tm_polygons()

#bbox expands the extent of the map so all data points are detected 
tmap_mode("view")+
tm_shape(shelf, bbox = sdat) +
  tm_polygons() +
   tm_borders("white", lwd = .5)
  tm_shape(aus) + 
  tm_polygons() + 
  tm_shape(sdat) + 
  tm_dots(col = "purple")+
    tm_basemap("Esri.WorldImagery") +  tm_tiles("Stamen.TonerLabels", ) 
  

```

##6.14 Exploring t_map 
```{r}
vignette('tmap-getstarted')

#Exercise to learn about accessing nice colour schemes such as virids: 

#loading required packages 
# for loading our data
library(raster)
library(readr)
library(readxl)
library(sf)
# for datasets
#install.packages("maps")
#install.packages("spData")
library(maps)
library(spData)
# for creating animations
#install.packages("magick")
library(magick)
# for plotting
#install.packages("grid")
#install.packages("viridis")
library(grid)
library(tmap)
library(viridis)

#Loading the data required 
# load shapefile for bavaria
bavaria <- read_sf("E:/github (1)/github/MB5370-Module04/data/bavaria.shp")
# load raster file for europe
europe_raster <- raster("E:/github (1)/github/MB5370-Module04/data/elevation1x1_new.tif")
# load shapefile for world
world_shape <- read_sf("E:/github (1)/github/MB5370-Module04/data/ne_50m_admin_0_countries.shp")

# keep only europe
europe_shape <- world_shape[world_shape$CONTINENT == "Europe",]

# use world.cities from the maps package
# keep only cities with at least 1 million inhabitants
cities <- world.cities[world.cities$pop >= 1000000, ]

# turn it into an sf object
cities <- cities %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326) %>%
  st_cast("POINT")

# keep only the cities that are in europe
cities <- st_intersection(cities, st_union(europe_shape))

# turn the europe object into a MULTILINESTRING
europe_shape <- st_cast(europe_shape, "MULTILINESTRING")
communities <- read_sf("gmd_ex.shp")

# keep only the ones in rosenheim
rosenheim <- communities[communities$BEZ_KRS == "Rosenheim", ]

# load the csv file for honey production in the us
honey_csv <- read_csv("honeyproduction.csv")

# load the xlsx file for abbreviations of the us states
abbrev <- read_xlsx("abbrev.xlsx")

# load honey shapefile
honey_sf <- read_sf("honey.shp")


```


##6.15 Exporting your map 
```{r}
#saving you map 
tmap_save()
```

